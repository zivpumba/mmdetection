{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d156212-3422-43a8-bc8d-187b667038d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://pumbatrainingdata/cars_detector/dataset/with_attributes/v5_0/ /home/ubuntu/mmdetection/data/v5_0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66645113-dd6e-49c9-8d61-507a35cb01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/open-mmlab/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet import datasets\n",
    "import mmdet.apis\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import (collect_env, get_device, get_root_logger,\n",
    "                         replace_cfg_vals, setup_multi_processes,\n",
    "                         update_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e80dcd-bd1d-4ff4-ab66-4bd8c2a8a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = 'retinanet_r50_fpn_mstrain_640-800_3x_coco-car_detector-trial'\n",
    "EXP_NAME = 'exp23'\n",
    "VERSION = 'v5_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c8fb33-92f2-4e48-9228-7005623845d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/mmdetection/training_notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cb3027-fa66-4393-89a5-fa43f5dd3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/home/ubuntu/mmdetection/data/v5_0/image_set': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"/home/{getpass.getuser()}/mmdetection\")\n",
    "!mv /home/{getpass.getuser()}/mmdetection/data/{VERSION}/image_set /home/{getpass.getuser()}/mmdetection/data/."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcfc1eb7-355c-4271-a12f-45a6f27d5908",
   "metadata": {},
   "source": [
    "!cd /home/{getpass.getuser()}/mmdetection/data/{VERSION}; coco-split \\\n",
    "    --has_annotations \\\n",
    "    --valid_ratio .2 \\\n",
    "    --test_ratio .1 \\\n",
    "    --annotations_file ../{VERSION}/det_{VERSION}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de1f4d-3e47-40eb-9a9d-08a6b52d182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python tools/train-Copy1.py configs/costume/{CONFIG_NAME}.py --work-dir work_dirs/{EXP_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594c8b3-55f6-4239-9c32-f5413d1a0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python tools/test.py configs/costume/{CONFIG_NAME}.py work_dirs/{EXP_NAME}/latest.pth --out work_dirs/{EXP_NAME}/results.pkl --eval bbox --show-dir work_dirs/{EXP_NAME}/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346921f-db64-4c40-8852-77cd0e92b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/analysis_tools/analyze_results.py \\\n",
    "      configs/costume/{CONFIG_NAME}.py \\\n",
    "      work_dirs/{EXP_NAME}/results.pkl \\\n",
    "      work_dirs/{EXP_NAME}/results_analysis \\\n",
    "      --topk 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065bd7f-43ed-402b-9805-4ccd58b472af",
   "metadata": {},
   "source": [
    "# Clean disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1fad6-13e5-4cae-876a-ac2ae94ff4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/ubuntu/.local/share/Trash/*\n",
    "!rm -rf /home/ubuntu/.cache/wandb/artifacts/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9858856-bcfc-4b25-8b57-c7fe5efbc4e7",
   "metadata": {},
   "source": [
    "# Inference model and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509e310-a83d-4469-823e-130a0a3a07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"aws s3 sync s3://pumbatrainingdata/binary_model/images /home/ubuntu/Vision/images --quiet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba0041-3bf5-4bcf-abd1-9cac838e2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fb117-a3ae-4429-bf5a-17ea4a271239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import getpass \n",
    "import numpy as np\n",
    "from random import sample\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "\n",
    "\n",
    "sys.path.append('Vision/DataManagement')\n",
    "os.chdir(f\"/home/{getpass.getuser()}\")\n",
    "from utils.inference.inference import MMdetDocker, RunInference\n",
    "import utils.core.common_utils as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554c338-f47d-4f8a-871c-a96809705315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_get_predicions(image_path):\n",
    "    url_serve = \"http://odworkersgpu-asg-1-1734987265.eu-central-1.elb.amazonaws.com/detect-img\"\n",
    "    header = {\"content-type\": \"image\"}\n",
    "    response = requests.post(url=url_serve, files={\"file\": (\"filename\", open(image_path, \"rb\"), \"image/jpeg\")}, json={})\n",
    "    return response.json()[0]\n",
    "\n",
    "\n",
    "def plot_predictions(result, image, yolo = False):\n",
    "\n",
    "    if yolo:\n",
    "        x1, y1, x2, y2 = map(int, result[:-1])\n",
    "        score = \"{:.2f}\".format(result[-1])\n",
    "    else:\n",
    "        x1, y1, x2, y2 = map(int, result['bbox'])\n",
    "        score = \"{:.2f}\".format(result['score'])\n",
    "    image = cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "    image = cv2.putText(image,\n",
    "                        score, \n",
    "                        (x1, y1),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.2,\n",
    "                        (0, 0, 0),\n",
    "                        1,\n",
    "                        cv2.LINE_AA, False)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0b1db-3379-4001-b592-4070f6fcf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob(f\"/home/ubuntu/Vision/images/large_images/*.jpg\")\n",
    "len(test_images), test_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c0f14-717b-4478-bfbf-66e547f5e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_images = sample(test_images,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2fd37-7f27-42db-a970-16c3964ce082",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image_path = f\"/home/ubuntu/Vision/animation/yolo-v1_0-4_0\"\n",
    "results_dict = dict()\n",
    "for i, name in tqdm(enumerate(inference_images)):\n",
    "    image_name = os.path.basename(name)\n",
    "    raw_image_path = f\"{prediction_image_path}/test/{image_name}\"\n",
    "    shutil.copy2(name, raw_image_path)\n",
    "    raw_image = cv2.imread(raw_image_path)\n",
    "    image = cv2.resize(raw_image, (320, 240), interpolation = cv2.INTER_AREA)\n",
    "    cu.save_image(image, raw_image_path)\n",
    "\n",
    "    infer1 = RunInference(url_serve='http://127.0.0.1:8080/predictions', image_path=raw_image_path, model_name='exp13')\n",
    "    infer2 = RunInference(url_serve='http://127.0.0.1:8090/predictions', image_path=raw_image_path, model_name='exp20')\n",
    "    \n",
    "    resultsYOLO = yolo_get_predicions(raw_image_path)\n",
    "    results1 = infer1.get_predicions()\n",
    "    results2 = infer2.get_predicions()\n",
    "\n",
    "    imageYOLO = image.copy()\n",
    "    image1 = image.copy()\n",
    "    image2 = image.copy()\n",
    "    \n",
    "    for resultyolo, result1, result2 in zip(resultsYOLO, results1, results2):\n",
    "        if result1['score'] > 0.8:\n",
    "            image1 = plot_predictions(result1, image1)\n",
    "        if result2['score'] > 0.8:\n",
    "            image2 = plot_predictions(result2, image2)\n",
    "        if resultyolo[-1] > 0.8:\n",
    "            imageYOLO = plot_predictions(resultyolo, imageYOLO, yolo = True)\n",
    "            \n",
    "    results_dict[i] = {\n",
    "    \"image\": os.path.basename(raw_image_path),\n",
    "    \"prediction\": {\n",
    "        \"yolo\": resultyolo,\n",
    "        \"exp13\": result1,\n",
    "        \"exp20\": result2\n",
    "    }\n",
    "}\n",
    "    cu.save_image(np.concatenate([imageYOLO, image1, image2], axis=1), f\"{prediction_image_path}/{image_name.replace('.jpg', '_pr.jpg')}\")\n",
    "    # plt.figure(figsize=(20,20)); plt.imshow(np.concatenate([imageYOLO, image1, image2], axis = 1)); plt.show()\n",
    "pd.DataFrame(results_dict).to_json(f\"/home/ubuntu/Vision/animation/yolo-v1_0-4_0/results/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c403cec-ea32-4b37-91f5-911ff7a42cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cu.clean_root('/home/ubuntu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509fa80-7849-489e-b284-41d8ad5761e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/ubuntu/Vision/animation; zip -rq yolo-v1_0-4_0.zip yolo-v1_0-4_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb1a3a-bc69-4f99-ab8a-6b8123b9997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp /home/ubuntu/Vision/animation/yolo-v1_0-4_0.zip s3://pumbatrainingdata/cars_detector/forensics/yolo-v1_0-4_0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0940c-ff5e-40f8-8a13-0fe54345f0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
